{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4995,
     "status": "ok",
     "timestamp": 1614106353811,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "cNJa0Z4C1jXh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "work_dir = '/home/abhijit/nat/Object-Detection'\n",
    "data_dir = work_dir+'/data/'\n",
    "util_dir = work_dir+'/data_utilities/'\n",
    "os.chdir(work_dir)\n",
    "sys.path.append(util_dir)\n",
    "sys.path.append(data_dir)\n",
    "\n",
    "import wv_util as wv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageDraw \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from read_write import *\n",
    "import shutil\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21011,
     "status": "ok",
     "timestamp": 1614106379543,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "uVS_62Kx1jXo",
    "outputId": "f9337eb3-cd53-4f4b-e951-dfe1a9f016f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601937/601937 [00:03<00:00, 163087.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading our labels\n",
    "coords, chips, classes = wv.get_labels(data_dir+'xView_train.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1614106381131,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "21gQ7pzbQDkZ"
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open(util_dir+'xview_class_labels.txt') as f:\n",
    "    for row in csv.reader(f):\n",
    "        labels[int(row[0].split(\":\")[0])] = row[0].split(\":\")[1]\n",
    "\n",
    "valid_labels = list(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d606klytlSMz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_chip_names = load(\"valid_chip_names.pkl\")\n",
    "\n",
    "id2label = load(\"class_to_label_map.pkl\")\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fixed-wing Aircraft': '11',\n",
       " 'Small Aircraft': '12',\n",
       " 'Cargo Plane': '13',\n",
       " 'Helicopter': '15',\n",
       " 'Passenger Vehicle': '17',\n",
       " 'Small Car': '18',\n",
       " 'Bus': '19',\n",
       " 'Pickup Truck': '20',\n",
       " 'Utility Truck': '21',\n",
       " 'Truck': '23',\n",
       " 'Cargo Truck': '24',\n",
       " 'Truck w/Box': '25',\n",
       " 'Truck Tractor': '26',\n",
       " 'Trailer': '27',\n",
       " 'Truck w/Flatbed': '28',\n",
       " 'Truck w/Liquid': '29',\n",
       " 'Crane Truck': '32',\n",
       " 'Railway Vehicle': '33',\n",
       " 'Passenger Car': '34',\n",
       " 'Cargo Car': '35',\n",
       " 'Flat Car': '36',\n",
       " 'Tank car': '37',\n",
       " 'Locomotive': '38',\n",
       " 'Maritime Vessel': '40',\n",
       " 'Motorboat': '41',\n",
       " 'Sailboat': '42',\n",
       " 'Tugboat': '44',\n",
       " 'Barge': '45',\n",
       " 'Fishing Vessel': '47',\n",
       " 'Ferry': '49',\n",
       " 'Yacht': '50',\n",
       " 'Container Ship': '51',\n",
       " 'Oil Tanker': '52',\n",
       " 'Engineering Vehicle': '53',\n",
       " 'Tower crane': '54',\n",
       " 'Container Crane': '55',\n",
       " 'Reach Stacker': '56',\n",
       " 'Straddle Carrier': '57',\n",
       " 'Mobile Crane': '59',\n",
       " 'Dump Truck': '60',\n",
       " 'Haul Truck': '61',\n",
       " 'Scraper/Tractor': '62',\n",
       " 'Front loader/Bulldozer': '63',\n",
       " 'Excavator': '64',\n",
       " 'Cement Mixer': '65',\n",
       " 'Ground Grader': '66',\n",
       " 'Hut/Tent': '71',\n",
       " 'Shed': '72',\n",
       " 'Building': '73',\n",
       " 'Aircraft Hangar': '74',\n",
       " 'Damaged Building': '76',\n",
       " 'Facility': '77',\n",
       " 'Construction Site': '79',\n",
       " 'Vehicle Lot': '83',\n",
       " 'Helipad': '84',\n",
       " 'Storage Tank': '86',\n",
       " 'Shipping container lot': '89',\n",
       " 'Shipping Container': '91',\n",
       " 'Pylon': '93',\n",
       " 'Tower': '94'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2idx(labels):\n",
    "    return {label:label2id[label] for label in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx(['Cargo Truck','Truck w/Box', 'Truck w/Flatbed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn0x6Ta3oVpP"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(classes, return_counts=True)\n",
    "class_counts = {k:0 for k in list(unique.astype('int64'))}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4824302,
     "status": "ok",
     "timestamp": 1613776964508,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "1k87CjPk4mq7",
    "outputId": "70c68bfc-7538-44ac-bc5b-dbb6ece17681"
   },
   "source": [
    "org_data_dir = data_dir+'train_images/'\n",
    "tgt_data_dir = data_dir+'new_train_images/'\n",
    "chip_names = list(np.unique(chips))\n",
    "k = 0\n",
    "\n",
    "imgs_processed = 0\n",
    "\n",
    "with tqdm(total=len(chip_names), position=0, leave=True) as pbar:\n",
    "\n",
    "  for chip_name in tqdm(chip_names, position=0, leave=True):\n",
    "\n",
    "    if chip_name in valid_chip_names:\n",
    "\n",
    "      chip = np.array(Image.open(org_data_dir+chip_name))\n",
    "\n",
    "      chip_bboxes = coords[chips==chip_name]\n",
    "      bbox_classes = classes[chips==chip_name].astype(np.int64)\n",
    "      imgs_processed += 1\n",
    "      for i in range(len(chip_bboxes)):\n",
    "\n",
    "        cropped_img = chip[int(chip_bboxes[i][1])-10:int(chip_bboxes[i][3])+10, int(chip_bboxes[i][0])-10:int(chip_bboxes[i][2])+10]\n",
    "\n",
    "        if cropped_img.shape[0] > 0 and cropped_img.shape[1] > 0:\n",
    "\n",
    "          im = Image.fromarray(cropped_img)\n",
    "          im.save(tgt_data_dir+str(bbox_classes[i])+'/'+str(k+1)+'.jpg')\n",
    "          k += 1\n",
    "          class_counts[bbox_classes[i]] += 1\n",
    "\n",
    "    pbar.update()\n",
    "\n",
    "print(\"\\nNumber of extracted images:\", k)\n",
    "print(\"Number of chips processed:\", imgs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(data_dir+'new_t',transform=transform,)\n",
    "\n",
    "#trainset, valset = random_split(dataset, [189829, 81355])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=25, shuffle=True)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dataset.targets,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = [id2label[idx_to_class[i]] for i in range(len(dataset.classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "show(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7*len(dataset)\n",
    "val_size = 0.3*len(dataset)\n",
    "print(\"full size\",len(dataset))\n",
    "print(\"train size\",train_size)\n",
    "print(\"val size\",val_size)\n",
    "189829+81355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "def plot_classes_preds(images, labels):\n",
    "    \n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for idx in np.arange(len(images)):\n",
    "        ax = fig.add_subplot(5, 5, idx+1, xticks=[], yticks=[])\n",
    "        ax.set_title(id2label[idx_to_class[labels[idx].item()]])\n",
    "        matplotlib_imshow(images[idx])\n",
    "    return fig\n",
    "#writer = SummaryWriter('runs/Object_detection_experiment_'+str(np.random.randint(0,1000)),flush_secs=1)\n",
    "#writer.add_figure('Images and labels', plot_classes_preds(images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes_preds(images, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1193968,
     "status": "ok",
     "timestamp": 1613779493024,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "kX-bASRrt76o",
    "outputId": "06acb43d-e988-4059-81f1-b9ce8150f277"
   },
   "source": [
    "new_pixel_areas = []\n",
    "old_pixel_areas = []\n",
    "low_thresh = 6\n",
    "high_thresh = 10\n",
    "filtered_images_count = 0\n",
    "filtered_image_dir = data_dir+'new_train_images_filtered/'\n",
    "with tqdm(total=60, position=0, leave=True) as pbar:\n",
    "    for subdir, dirs, files in tqdm(os.walk(data_dir+'new_train_images/'), position=0, leave=True):\n",
    "        for filename in files:\n",
    "            filepath = subdir + os.sep + filename\n",
    "            if filepath.endswith(\".jpg\"):\n",
    "                img_PIL = Image.open(filepath)\n",
    "                img = np.array(img_PIL)\n",
    "                area = img.shape[0]*img.shape[1]\n",
    "                old_pixel_areas.append(area)\n",
    "                if (np.log(area) < high_thresh) and (np.log(area) > low_thresh):\n",
    "                    img_PIL.save(filtered_image_dir+subdir[-2:]+os.sep+filename)\n",
    "                    filtered_images_count+=1\n",
    "                    new_pixel_areas.append(area)\n",
    "                    \n",
    "        pbar.update()\n",
    "print(\"filtered images\",filtered_images_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AueqaC_gBnJV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343542,
     "status": "ok",
     "timestamp": 1614106748089,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "sW0oK6W-_5n1",
    "outputId": "81ca46ff-c713-4cc5-9b07-df208252388b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       -1        729\n",
      "                       -1      16782\n",
      "      Fixed-wing Aircraft        910\n",
      "             Pickup Truck       3185\n",
      "                       -1       1809\n",
      "                       -1      10330\n",
      "               Helicopter        836\n",
      "                       -1        856\n",
      "                       -1        938\n",
      "                       -1       6892\n",
      "                      Bus       1026\n",
      "                Small Car       1145\n",
      "                       -1       1820\n",
      "           Small Aircraft        606\n",
      "        Passenger Vehicle        703\n",
      "            Utility Truck       1609\n",
      "              Cargo Plane       1351\n",
      "                       -1        705\n",
      "                       -1       1455\n",
      "                       -1     213429\n",
      "                       -1       1596\n",
      "                       -1       4057\n",
      "272769\n"
     ]
    }
   ],
   "source": [
    "total_num_of_images = 0\n",
    "class_counts = {}\n",
    "for subdir, dirs, files in os.walk(data_dir+'train_images_22classes'):\n",
    "    if len(files)>0:\n",
    "        print(f'{id2label.get(subdir[-2:],-1):>25} {len(files):>10}')\n",
    "        class_counts[id2label.get(subdir[-2:],-1)] = len(files)\n",
    "        total_num_of_images+=len(files)\n",
    "print(total_num_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "a = copy.deepcopy(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_count = pd.DataFrame(list(class_counts.values()))\n",
    "c_count[c_count[0]>700].values[1:]\n",
    "small_subset_class = {}\n",
    "a = 0\n",
    "for label, count in class_counts.items():\n",
    "    \n",
    "    if count > 700 and count < 250000:\n",
    "        small_subset_class[label] = count\n",
    "        #print(label,count)\n",
    "        a+=count\n",
    "print(\"total\",a)\n",
    "print(small_subset_class)\n",
    "print(\"total confirm\",sum(list(small_subset_class.values())))\n",
    "print(\"len\",len(small_subset_class))\n",
    "#save('class_counts_24classes.pkl',small_subset_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = load('class_counts_24classes.pkl')\n",
    "#os.mkdir(data_dir+'train_images_24classes')\n",
    "# for i in list(new_classes.keys()):\n",
    "#     os.mkdir(data_dir+'train_images_24classes/'+str(int(label2id[i])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f = data_dir+'new_train_images_filtered/'\n",
    "t = data_dir+'train_images_24classes/'\n",
    "valid_c = list(new_classes.keys())\n",
    "count1 = 0\n",
    "for subdir, dirs, files in os.walk(data_dir+'new_train_images_filtered/'):\n",
    "    a = subdir[-2:]\n",
    "    if id2label.get(a,-1) in valid_c:\n",
    "        for filename in files:\n",
    "            #print(subdir+os.sep+filename)\n",
    "            shutil.copy(subdir+os.sep+filename,t+os.sep+a)\n",
    "            count1+=1\n",
    "print(\"total count sanity\", count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'value' must be an instance of str or bytes, not a int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-91cf4b6be8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbarh\u001b[0;34m(y, width, height, left, align, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m     return gca().barh(\n\u001b[0;32m-> 2503\u001b[0;31m         y, width, height=height, left=left, align=align, **kwargs)\n\u001b[0m\u001b[1;32m   2504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbarh\u001b[0;34m(self, y, width, height, left, align, **kwargs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'orientation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         patches = self.bar(x=left, height=height, width=width, bottom=y,\n\u001b[0;32m-> 2631\u001b[0;31m                            align=align, **kwargs)\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2411\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_process_unit_info\u001b[0;34m(self, xdata, ydata, kwargs)\u001b[0m\n\u001b[1;32m   2188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_single_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xunits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_single_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yunits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_process_single_axis\u001b[0;34m(data, axis, unit_name, kwargs)\u001b[0m\n\u001b[1;32m   2170\u001b[0m                 \u001b[0;31m# We only need to update if there is nothing set yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhave_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m                     \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0;31m# Check for units in the kwargs, and if present update axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mupdate_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0mneednew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36mdefault_units\u001b[0;34m(data, axis)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# the conversion call stack is default_units -> axis_info -> convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# OrderedDict just iterates over unique values in data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvertible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# this will only be called so long as convertible is True.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_isinstance\u001b[0;34m(_types, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m                     \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" or \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m                     type_name(type(v))))\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'value' must be an instance of str or bytes, not a int"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[10,10])\n",
    "class_counts = sorted(class_counts.items(), key=lambda class_counts: class_counts[1])\n",
    "class_counts = {k: v for k, v in class_counts}\n",
    "real_count = list(class_counts.values())\n",
    "total_count = np.sum(real_count)\n",
    "bars = plt.barh(list(class_counts.keys()), np.log(np.array(list(class_counts.values()))), edgecolor='k',color='skyblue')\n",
    "\n",
    "for i,bar in enumerate(bars): \n",
    "    width = bar.get_width() +0.1\n",
    "    label_y_pos = bar.get_y() + 0.2 + bar.get_height() // 2\n",
    "    #ax.text(width,label_y_pos, s=f'{real_count[i]}',fontweight='bold',fontdict={'fontsize':14})\n",
    "    ax.text(width,label_y_pos, s=f'{np.round(1.0*real_count[i]/total_count,4)*100.0:.2f} %, {real_count[i]}',fontweight='bold',fontdict={'fontsize':14})\n",
    "    \n",
    "    if i > 44:\n",
    "        bar.set_color('#8f9805')\n",
    "        bar.set_edgecolor('k')\n",
    "\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(14)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color='#8f9805', lw=4)]\n",
    "#plt.legend(custom_lines,['Top 15 most frequent classes'],loc=5,fontsize='large')\n",
    "plt.title('Class Distribution (number of classes = ' + str(len(real_count))+')',fontdict={'fontsize':15,'fontweight':'bold'})\n",
    "plt.xlabel('Frequency (log scale)', fontdict={'fontsize':15,'fontweight':'bold'})\n",
    "plt.ylabel('Class', fontdict={'fontsize':15,'fontweight':'bold'})\n",
    "plt.xlim(0,14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "for subdir, dirs, files in os.walk(data_dir+'train_images_top5_weak/train'):\n",
    "    c = 0\n",
    "    for filename in files:\n",
    "        #print(subdir+'/'+filename)\n",
    "        c+=1\n",
    "        if c > 620:\n",
    "            #print(\"cut here\")\n",
    "            os.remove(subdir+'/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('test_saving1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('test_saving2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_directory = os.path.join('./runs', os.sep, 'resnet50',os.sep,'blah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('old_pixel_areas.pkl','rb')\n",
    "old_pixel_areas = pickle.load(f)\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.hist(np.log(np.array(old_pixel_areas)),bins=50,color='skyblue',ec=\"k\")\n",
    "\n",
    "plt.title('Histogram of pixel areas before resampling \\n Total number of images = 593,091',fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.xlabel('Frequency (log scale)', fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.ylabel('Class', fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.xlim(5,14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('new_pixel_areas.pkl','rb')\n",
    "new_pixel_areas = pickle.load(f)\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.hist(np.log(np.array(new_pixel_areas)),bins=20,color='skyblue',ec=\"k\")\n",
    "\n",
    "plt.title('Histogram of pixel areas after resampling \\n Total number of images = 581,470',fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.xlabel('Frequency (log scale)', fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.ylabel('Class', fontdict={'fontsize':14,'fontweight':'bold'})\n",
    "plt.xlim(5,14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NlkuBRX2L8Dv"
   },
   "source": [
    "!mkdir ../backup_new_train_images_2/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "W4MIF4q3MDK0"
   },
   "source": [
    "!cp -r ../new_train_images_2/ ../backup_new_train_images_2/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HYUbIKQR24z",
    "outputId": "f7453e00-3ff4-487d-c5a0-4d0f0facdee4"
   },
   "source": [
    "!rm -r data/new_train_images_filtered/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L578NP41NDSv",
    "outputId": "2b903862-c7b4-4ca2-cd0c-3e4dd806fc8a"
   },
   "source": [
    "!mkdir ../new_train_images_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "T0jqvGjly4MM"
   },
   "source": [
    "for i in list(unique.astype('int64')):\n",
    "  os.mkdir(data_dir+'new_train_images/'+str(i))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "k4UEWj1-Bvat"
   },
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ste3stp6S3WU"
   },
   "source": [
    "!mkdir data/new_train_images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "h35QU-I1LHpN"
   },
   "source": [
    "os.mkdir(data_dir+'new_train_images_filtered')\n",
    "for i in list(id2label.keys()):\n",
    "  os.mkdir(data_dir+'new_train_images_filtered/'+str(int(i)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(unique)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(id2label.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94552,
     "status": "ok",
     "timestamp": 1614106342462,
     "user": {
      "displayName": "Natnael Taye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLsOfPayUDuhnA0fYfbsxcWRCTOwPzHALWfRPL8g=s64",
      "userId": "14979943471241687010"
     },
     "user_tz": 300
    },
    "id": "OEGNHHlN1pKO",
    "outputId": "61b9eed3-b286-4f15-c830-3155af7dd8f0"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests \n",
    "from tqdm import tqdm\n",
    "file_url = [\"https://d307kc0mrhucc3.cloudfront.net/train_images.tgz?Expires=1614387555&Signature=NBrilUhHPZgQPsWZLnt1z~qxZw3joeiA7X9wD0FxZBFdrwZgURgew0q2RJitOpwrs~DanTIpBESPz3kB6wvpD89-Xhyn9L3GxQioWSylbmkKHRKNdhCvmnwOsKuJ11vrBogBDdtilVlfnGeIT1e9ERh~fYkfKJQlpP8wEUJE3TVvSjSZ6yb7fpeq6XlQEgXiky7~wxYtr457D3c5fwLJdotnDFJAVU2rDnhevv4~PhLwDXFCdB5Fq-MLqCAn5gOAtZtuW643r~hluwiov9Xezhk2uvAaQeQJNwupl3DfFc4lbxYVaiXRP5-ApCi~U~cYq0D-BUqF3XxYDN4pRYXc7A__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\",\n",
    "            \"https://d307kc0mrhucc3.cloudfront.net/train_labels.tgz?Expires=1614387555&Signature=e~93prunA1dNTN22YV4-fJ4VOnFjWce1DiU2kLkmZkMu5UbEesBh5Hrqr9gRsF~6F6-hkoi-bGbDyGS2h7DZ9cAATbNV7Ka8ILgxl75xhR468e6Sahzo4IeJdJFhoJ4TNS~UoJX4s~mNjwhOAeJ-BhKr2nJ~aB9G1iRV-MNi0Q~ibtHxv3We7KWG3p9PNM-4nnOTGnKK9OwTlhMesXBnkk206ahOJVidlfL3-XlaW6zQiPHeAX4X-BA8xHbcR5JS99Y6FvL-u5nioNvI2MTPWcSyJZuWAp9q1E9jZ8yS~N2qoENUq0XLMrTCpDgjlrAuXmuHjTJxJo50uwSj2nPkg__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\"]            \n",
    "r = requests.get(file_url[1], stream = True) \n",
    "\n",
    "with open(work_dir+'/train_labels.tgz', \"wb\") as file:\n",
    "    for block in r.iter_content(chunk_size = 1024):\n",
    "        if block:\n",
    "            file.write(block) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders  # or import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(data_dir+'train_images_24classes/', output=data_dir+'train_images_24classess_split', seed=1337, ratio=(.7, .3), group_prefix=None) # default values\n",
    "\n",
    "# Split val/test with a fixed number of items e.g. 100 for each set.\n",
    "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
    "#splitfolders.fixed(\"input_folder\", output=\"output\", seed=1337, fixed=(100, 100), oversample=False, group_prefix=None) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!mkdir data/train_images_24classes_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir+'train_images_24classess_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 6), nn.Linear(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net.children())[-1].named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(10, 3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "output = net(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = output.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.extend(b.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-msi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0.0, 0.0, 0\n",
    "    \n",
    "    for data, _ in loader:\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "        \n",
    "    mean = channels_sum/num_batches\n",
    "    std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(data_dir+'train_images_22classes_split/train',transform=transform,)\n",
    "\n",
    "#trainset, valset = random_split(dataset, [189829, 81355])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2532, 0.2125, 0.1867]), tensor([0.1537, 0.1390, 0.1325]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_std(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_new = torch.utils.data.DataLoader(dataset, batch_size=len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2532, 0.2125, 0.1867])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean([0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1537, 0.1390, 0.1325])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.std([0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(5,3,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(x,[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(x[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "resnet50 = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"model\":<35} {\"requires grad\":<10}')\n",
    "for name, param in resnet50.named_parameters():\n",
    "    print(f'{name:<35} {str(param.requires_grad):<10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"model\":<35} {\"requires grad\":<10}')\n",
    "for name, param in resnet50.named_parameters():\n",
    "      layer, attr = os.path.splitext(name)\n",
    "    print(f'{name:<35} {str(param.requires_grad):<10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    layer, attr = os.path.splitext(name)\n",
    "    print(\"layer\",layer, \"attr\", attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_loss50 = pd.read_csv('run-resnet50_Saturday_13_March_2021_04h_22m_07s-tag-Test_Average loss.csv')\n",
    "test_acc50 = pd.read_csv('run-resnet50_Saturday_13_March_2021_04h_22m_07s-tag-Test_Accuracy.csv')\n",
    "test_loss18 = pd.read_csv('run-resnet18_Saturday_13_March_2021_15h_23m_49s-tag-Test_Average loss.csv')\n",
    "test_acc18 =pd.read_csv('run-resnet18_Saturday_13_March_2021_15h_23m_49s-tag-Test_Accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss50_x = test_loss50.Step.values\n",
    "test_loss50_y = test_loss50.Value.values\n",
    "\n",
    "test_loss18_x = test_loss18.Step.values\n",
    "test_loss18_y = test_loss18.Value.values\n",
    "\n",
    "test_acc50_x = test_acc50.Step.values\n",
    "test_acc50_y = test_acc50.Value.values\n",
    "\n",
    "test_acc18_x = test_acc18.Step.values\n",
    "test_acc18_y = test_acc18.Value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss50_x,test_loss50_y , 'b', label='ResNet50')\n",
    "plt.plot(test_loss18_x[:49],test_loss18_y[:49] , 'r', label='ResNet18')\n",
    "plt.title('Test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc50_x, test_acc50_y , 'b', label='ResNet50')\n",
    "plt.plot(test_acc18_x[:49],test_acc18_y[:49] , 'r', label='ResNet18')\n",
    "plt.title('Test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('./imbalanced-dataset-sampler')\n",
    "!python setup.py install\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(data_dir+'train_images_22classes_split/train',transform=transform,)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.unique(dataset.targets, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0043909 , 0.00681392, 0.00426372, 0.00283802, 0.0063253 ,\n",
       "       0.00329987, 0.00391566, 0.00341365, 0.00329317, 0.00536145,\n",
       "       0.00480589, 1.        , 0.01491968, 0.00753681, 0.0084739 ,\n",
       "       0.07862784, 0.04839357, 0.00400937, 0.01900268, 0.03228916,\n",
       "       0.00747657, 0.00852744])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(x)/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(one_batch[1].numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utilities.read_write import *\n",
    "index_to_class = {index: classs for classs, index in dataset.class_to_idx.items()} \n",
    "\n",
    "class_to_label = load(\"class_to_label_map.pkl\")\n",
    "\n",
    "class_names = [class_to_label[index_to_class[i]] for i in unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_images = 0\n",
    "class_counts = {}\n",
    "for subdir, dirs, files in os.walk(data_dir+'train_images_24classes_split/train'):\n",
    "    if len(files)>0:\n",
    "        print(f'{id2label.get(subdir[-2:],-1):>25} {len(files):>10}')\n",
    "        class_counts[id2label.get(subdir[-2:],-1)] = len(files)\n",
    "        total_num_of_images+=len(files)\n",
    "print(total_num_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "balanced_train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    sampler=ImbalancedDatasetSampler(dataset),\n",
    "    batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_one_batch = next(iter(balanced_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_unique, balanced_counts = np.unique(balanced_one_batch[1].numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [class_to_label[index_to_class[i]] for i in balanced_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,23):\n",
    "    os.mkdir('./data/train_images_22classes/'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh data/train_images_22classes/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 272769 files [30:44, 147.85 files/s] \n"
     ]
    }
   ],
   "source": [
    "import splitfolders  # or import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(data_dir+'train_images_22classes/', output=data_dir+'train_images_22classes_split', seed=1337, ratio=(.7, .3), group_prefix=None) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_object, save_object\n",
    "class_to_label = load_object(\"class_to_label_map.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11': 'Fixed-wing Aircraft',\n",
       " '12': 'Small Aircraft',\n",
       " '13': 'Cargo Plane',\n",
       " '15': 'Helicopter',\n",
       " '17': 'Passenger Vehicle',\n",
       " '18': 'Small Car',\n",
       " '19': 'Bus',\n",
       " '20': 'Pickup Truck',\n",
       " '21': 'Utility Truck',\n",
       " '23': 'Truck',\n",
       " '24': 'Cargo Truck',\n",
       " '25': 'Truck w/Box',\n",
       " '26': 'Truck Tractor',\n",
       " '27': 'Trailer',\n",
       " '28': 'Truck w/Flatbed',\n",
       " '29': 'Truck w/Liquid',\n",
       " '32': 'Crane Truck',\n",
       " '33': 'Railway Vehicle',\n",
       " '34': 'Passenger Car',\n",
       " '35': 'Cargo Car',\n",
       " '36': 'Flat Car',\n",
       " '37': 'Tank car',\n",
       " '38': 'Locomotive',\n",
       " '40': 'Maritime Vessel',\n",
       " '41': 'Motorboat',\n",
       " '42': 'Sailboat',\n",
       " '44': 'Tugboat',\n",
       " '45': 'Barge',\n",
       " '47': 'Fishing Vessel',\n",
       " '49': 'Ferry',\n",
       " '50': 'Yacht',\n",
       " '51': 'Container Ship',\n",
       " '52': 'Oil Tanker',\n",
       " '53': 'Engineering Vehicle',\n",
       " '54': 'Tower crane',\n",
       " '55': 'Container Crane',\n",
       " '56': 'Reach Stacker',\n",
       " '57': 'Straddle Carrier',\n",
       " '59': 'Mobile Crane',\n",
       " '60': 'Dump Truck',\n",
       " '61': 'Haul Truck',\n",
       " '62': 'Scraper/Tractor',\n",
       " '63': 'Front loader/Bulldozer',\n",
       " '64': 'Excavator',\n",
       " '65': 'Cement Mixer',\n",
       " '66': 'Ground Grader',\n",
       " '71': 'Hut/Tent',\n",
       " '72': 'Shed',\n",
       " '73': 'Building',\n",
       " '74': 'Aircraft Hangar',\n",
       " '76': 'Damaged Building',\n",
       " '77': 'Facility',\n",
       " '79': 'Construction Site',\n",
       " '83': 'Vehicle Lot',\n",
       " '84': 'Helipad',\n",
       " '86': 'Storage Tank',\n",
       " '89': 'Shipping container lot',\n",
       " '91': 'Shipping Container',\n",
       " '93': 'Pylon',\n",
       " '94': 'Tower'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label_22classes = {\n",
    "    \n",
    "    '1':'Plane',\n",
    "    '2':'Small Car',\n",
    "    '3':'PickupUtilityTruck',\n",
    "    '4':'CargoBoxFlatbedTrucks',\n",
    "    '5':'Truck Tractor',\n",
    "    '6':'Trailer',\n",
    "    '7':'Bus',\n",
    "    '8':'Passenger Car',\n",
    "    '9':'Cargo/Container Car',\n",
    "    '10':'Motorboat',\n",
    "    '11':'SailTugBoats',\n",
    "    '12':'FerryYacht',\n",
    "    '13':'Dump Truck',\n",
    "    '14':'TractorBulldozer',\n",
    "    '15':'Excavator',\n",
    "    '16':'Fishing Vessel',\n",
    "    '17':'Hut/Tent',\n",
    "    '18':'Shed',\n",
    "    '19':'Damaged Building',\n",
    "    '20':'Vehicle Lot',\n",
    "    '21':'Storage Tank',\n",
    "    '22':'Shipping container lot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Plane',\n",
       " '2': 'Small Car',\n",
       " '3': 'Pickup Utility Truck',\n",
       " '4': 'CargoBoxFlatbedTrucks',\n",
       " '5': 'Truck Tractor',\n",
       " '6': 'Trailer',\n",
       " '7': 'Bus',\n",
       " '8': 'Passenger Car',\n",
       " '9': 'Cargo/Container Car',\n",
       " '10': 'Motorboat',\n",
       " '11': 'SailTugBoats',\n",
       " '12': 'FerryYacht',\n",
       " '13': 'Dump Truck',\n",
       " '14': 'TractorBulldozer',\n",
       " '15': 'Excavator',\n",
       " '16': 'Fishing Vessel',\n",
       " '17': 'Hut/Tent',\n",
       " '18': 'Shed',\n",
       " '19': 'Damaged Building',\n",
       " '20': 'Vehicle Lot',\n",
       " '21': 'Storage Tank',\n",
       " '22': 'Shipping container lot'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_label_22classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object('class_to_label_22classes.pkl', class_to_label_22classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_object('class_to_label_22classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Plane',\n",
       " '2': 'Small Car',\n",
       " '3': 'Pickup Utility Truck',\n",
       " '4': 'CargoBoxFlatbedTrucks',\n",
       " '5': 'Truck Tractor',\n",
       " '6': 'Trailer',\n",
       " '7': 'Bus',\n",
       " '8': 'Passenger Car',\n",
       " '9': 'Cargo/Container Car',\n",
       " '10': 'Motorboat',\n",
       " '11': 'SailTugBoats',\n",
       " '12': 'FerryYacht',\n",
       " '13': 'Dump Truck',\n",
       " '14': 'TractorBulldozer',\n",
       " '15': 'Excavator',\n",
       " '16': 'Fishing Vessel',\n",
       " '17': 'Hut/Tent',\n",
       " '18': 'Shed',\n",
       " '19': 'Damaged Building',\n",
       " '20': 'Vehicle Lot',\n",
       " '21': 'Storage Tank',\n",
       " '22': 'Shipping container lot'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abhijit/nat/Object-Detection'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\r\n",
      " \u001b[34;42m__pycache__\u001b[0m/\r\n",
      " \u001b[34;42mcheckpoint\u001b[0m/\r\n",
      " \u001b[01;32mconfig.py\u001b[0m*\r\n",
      " \u001b[34;42mdata\u001b[0m/\r\n",
      " \u001b[34;42mdata_loader\u001b[0m/\r\n",
      " \u001b[34;42mdata_utilities\u001b[0m/\r\n",
      " \u001b[34;42mimbalanced-dataset-sampler\u001b[0m/\r\n",
      " \u001b[01;32mlr_finder.py\u001b[0m*\r\n",
      " \u001b[34;42mmodels\u001b[0m/\r\n",
      "\u001b[34;42m'models\\resnet'\u001b[0m/\r\n",
      " \u001b[34;42mobj-detection\u001b[0m/\r\n",
      " \u001b[01;32mrequirements.txt\u001b[0m*\r\n",
      " \u001b[01;32mresult.jpg\u001b[0m*\r\n",
      " \u001b[01;32mrun-resnet18_Saturday_13_March_2021_15h_23m_49s-tag-Test_Accuracy.csv\u001b[0m*\r\n",
      "\u001b[01;32m'run-resnet18_Saturday_13_March_2021_15h_23m_49s-tag-Test_Average loss.csv'\u001b[0m*\r\n",
      " \u001b[01;32mrun-resnet50_Saturday_13_March_2021_04h_22m_07s-tag-Test_Accuracy.csv\u001b[0m*\r\n",
      "\u001b[01;32m'run-resnet50_Saturday_13_March_2021_04h_22m_07s-tag-Test_Average loss.csv'\u001b[0m*\r\n",
      " \u001b[01;32mrun-resnet50_Saturday_13_March_2021_04h_22m_07s-tag-Train_loss.csv\u001b[0m*\r\n",
      " \u001b[34;42mruns\u001b[0m/\r\n",
      " \u001b[01;32mtrain.py\u001b[0m*\r\n",
      " \u001b[01;32mutils.py\u001b[0m*\r\n",
      " \u001b[01;32mworkspace.code-workspace\u001b[0m*\r\n",
      " \u001b[01;32mxView_Processing.ipynb\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      1.00      0.67         1\n",
      "     class 1       0.00      0.00      0.00         1\n",
      "     class 2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "t = print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"test.txt\", \"w\")\n",
    "\n",
    "print(\"Hello World\")\n",
    "\n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out.txt', 'w') as f:\n",
    "    \n",
    "    print(classification_report(y_true, y_pred, target_names=target_names),file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "xView_Processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
